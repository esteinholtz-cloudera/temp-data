{
  "Speaker": "Anca Dragan",
  "Start": "01:18:21",
  "End": "01:20:10",
  "Text": ". Yeah, absolutely. So, think some surprising bits, right. So we were talking before about, I'm a robot arm, it needs to move around, people carry stuff, put stuff away all of that. And now that robot has some initial objective that the programmer gave it so they can do all these things functional. It's capable of doing that. And now I noticed that it's doing something and maybe it's coming close to me, right? And maybe I'm the designer, maybe I'm the end user and this robot is now in my home I pushed it away. I put it away because, you know, it's a reaction to what the robot is currently doing and this is what we call physical human robot interaction. now there's a lot of, there's a lot of interesting work on how do you respond to physical human robot interaction? What should the robot do if such an event occurs? And there's sort of different schools of thought, it's, well, you know, you can sort of treat it the control theoretically and say this is a disturbance that you must reject. Um you can sort of treat it um more kind of heuristically and say I'm going to go into some like gravity compensation mode. So I'm easily maneuverable around, I'm going to go in the direction that the person pushed me. And, and to us, of realization has been that that is signal that communicates about the reward. Because if my robot was moving in an optimal way and I intervened, that means that I disagree with his notion of optimality, right, whatever it thinks is optimal is not actually optimal and sort of optimization problems aside, that means that the cost function, the reward function is is incorrect or at least is not what I want it to"
}