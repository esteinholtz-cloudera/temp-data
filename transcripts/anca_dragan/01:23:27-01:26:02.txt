{
  "Speaker": "Anca Dragan",
  "Start": "01:23:27",
  "End": "01:26:02",
  "Text": ", obey what? Right. Because we just talked about how you try to say what you want, but you don't always get it right. And you want these machines to do what you want. Not necessarily exactly what you say, you don't want them to take you literally. You want to what you say and interpret it in context. And that's what we do with the specified rewards. We don't take them literally anymore from the designer. Not we as a community. We as you know, some members of my group, we and some of our collaborators like Peter Beal and Stuart Russell, should have said, OK, the designer specified this thing, but I'm gonna interpret it not as this is the universal reward function that I shall always optimize always and forever. But as this is evidence about what the person wants, and I should interpret that evidence in the context of these situations that it was specified for. Because ultimately, that's what the designers thought about, that's what they had in mind and really them specifying reward function that works for me in all these situations is really kind of telling me that whatever behavior that incentivizes must be good behavior, respect too, thing that I should actually be optimizing for. And so now the robot has uncertainty about what it is that it should be what its reward function is. And then there's all these additional signals we've been finding that it can kind of continually learn from and adapt its understanding people want every time the person corrects it maybe they demonstrate maybe they stop. Hopefully not. Right. Um One really, really crazy one is the environment itself like our world. It's not, you know, you observe our world and the state of it and it's not that you're seeing behavior and you're saying, oh, people are making decisions that are rational, blah, blah, blah, it's, but, but our world is something that we've been acting with according to our preferences. So I have this example where the robot walks into my home and my shoes are laid down on the floor kind of in a line, right? It took effort to do that even though the doesn't see me doing this actually aligning the shoes. It should still be able to figure out that I want the shoes align because there's no way for them to have magically instantiated themselves in that way someone must have actually the time to do that. So it must be important. So the"
}