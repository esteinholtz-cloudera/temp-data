{
  "Speaker": "Anca Dragan",
  "Start": "00:55:45",
  "End": "00:57:54",
  "Text": "think the one hand that is inevitable here, right? Um I think on the other hand that when people characterize the problem as it's a bunch of rules that some people wrote down versus it's an end to end darl system or imitation learning, then maybe there's kind of something missing um from maybe that's more so for, instance, I think a very, very useful tool in this sort of problem both in how to generate the car's behavior and robots in general and how to model human beings is actually planning search optimization, right? So robotics is a sequential decision making problem. And when, when a robot can out on its own how to achieve its goal without hidden stuff and all that stuff, all the good stuff for motion planning, one on one, I think of that as very much A I not, this is some rule or something here, there's nothing rule based around that, right? It's just you're searching through a space and figuring out are you optimizing through a space and figure out what seems to be the right thing to do. And I think it's hard to just do that because you need to learn models of the world. And I think it's hard to just do the learning part where you don't bother with any of that then you're saying, well, I could do imitation, but then when I go off distribution, I'm really screwed. Or you can say I can do reinforcement learning, which adds a lot of robustness. But then you have to do either reinforcement learning in the real world, which sounds a little challenging or that trial and error, you know, or you have to do reinforcement learning and simulation. And then that means, well, guess what? You need to model things at least to model people, model the world enough that whatever policy you get of that is actually fine to roll out in the world and do some additional learning there. So"
}