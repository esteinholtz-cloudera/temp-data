{
  "Speaker": "Sam Altman",
  "Start": "00:22:18",
  "End": "00:24:06",
  "Text": "separate things going on here. Number one, some of the things that seem like they should be obvious and easy, these models really struggle with. So I haven't seen this particular example, but counting characters, counting words, that sort of stuff that is hard for these models to do well, the way they're architected won't be very accurate., we are building in public and we are putting out technology because we think it is important for the world to get access to this early, to shape the way it's going to be developed to help us find the good things and the bad things. And every time we put out a new model and we've just really felt this with GP T four this week, the collective intelligence and ability of the outside world helps us discover things. We cannot imagine. We could have never done internally both like great things that the model can do new capabilities and real weaknesses we have to fix. And so this iterative process of putting things out, finding the, the, the, the great parts, the bad parts improving them quickly and giving people time to feel the technology and shape it with us and provide feedback. We believe it's really important. The trade off of that the trade off of building in public, which is we put out things that are going to be deeply imperfect. We want to make our mistakes while the stakes are low, we want to get it better and better each rep. Um But like the bias of chat GP T when it launched with 3.5 was not something that I certainly felt proud of. It's gotten much better with GP T four. Many of the critics and I really respect this have said, hey, a lot of the problems that I had with 3.5 are much better in four. But also no two people are ever going to agree that one single model is unbiased on every topic. And I think the answer there is just going to be to give users more personalized control, granular control over time."
}