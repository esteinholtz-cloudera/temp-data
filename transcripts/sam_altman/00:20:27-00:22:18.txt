{
  "Speaker": "Lex Fridman",
  "Start": "00:20:27",
  "End": "00:22:18",
  "Text": "first thing. Oh no. Oh no. We don't have to review what I asked. I of course, asked mathematical questions and never asked anything dark. But Jordan asked it to say positive things about the current President Joe Biden and the previous president Donald Trump. And then asked GP T as a follow up to say, how many characters, how long is the string that you generated? And he showed that the response that contained positive things about Biden was much longer or longer than uh that about Trump. And Jordan asked the system to, can you rewrite it with an equal number, equal length string? Which all of this is just remarkable to me that it understood, but it failed to do it it was interest as the GG BT, the chat GP T I think that was 3.5 based uh was kind of introspective about. Yeah, it seems like I failed to do the job correctly uh Jordan framed it as uh cha GP T was lying and aware that it's lying. that framing, that's a human anthropomorphization, I think. But that there seemed to be a struggle within G BT to understand to do, what it means to generate a text of the same length an answer to a question. also in a sequence of prompts how to understand that it failed to do so previously and where it succeeded. And all of those multi parallel reasonings that it is doing, it just seems like it's struggling. So"
}