{
  "Speaker": "Lex Fridman",
  "Start": "01:11:43",
  "End": "01:13:59",
  "Text": "would be surreal to be able to interact in some way with the thing that's out there on another surface condition, direct connection. I think about artificial intelligence in that same way, which is building puts a mirror to us humans. It makes us wonder about what is intelligence, what is consciousness and what is actually valuable about human beings. When A A I system learns to play chess better than humans, you start to let go of this idea that humans are special because of intelligence. It's something else. the flame of human consciousness, it's the capacity to feel deeply, to sort of, to both suffer and to love all those things. And that somehow A I to me puts a mirror to that. You mentioned Hal 9000, you have to bring it up with these swarm bots crawling on the surface of your cocoon in space. I mean, right, let me uh steel man. The uh the hell 9000 perspective, poor guy just wanted to maintain the mission and the astronauts were, I mean, I, I don't know if people often talk about that, but you know, um doctors have to make difficult decisions too when there's limited resources, you actually do have to sacrifice human life often because you have to make decisions. And I think Hal is probably making that kind of decision about what, what's more important, the lives of individual astronauts or the mission. And I feel like a I when other humans will need to make these decisions it also feels like a I systems will need to help make those decisions. I don't know. I guess my question is about greater and greater collective intelligence by systems. you worry about that? What is the right way to solve this problem keeping a human in the loop? Do you think about this kind of stuff or are they sufficiently dumb? Now, the robots that's not yet on the horizon to think about?"
}