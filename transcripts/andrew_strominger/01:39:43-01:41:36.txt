{
  "Speaker": "Lex Fridman",
  "Start": "01:39:43",
  "End": "01:41:36",
  "Text": ". But you still don't understand deeply, especially because they're getting, know, especially language models. If you're paying attention, the systems that are able to generate text, they're able to have conversations. Chad GP T is the recent manifestation of that. They just seem to know everything they're trained on the internet. They seem to be very, very good at something that looks like reasoning, they're able to generate, you can ask them questions, they can answer questions. It just feels like this thing is intelligent,? And I could just see that being possible with physics, you ask any kind of physical question and they'll be able to very precise about a particular star system or a particular black hole. And you'll say, well, these are the numbers, it'll perfectly predict and then sure, you can understand how the neural network is. The architecture is structured actually for most of them. Now, they're very simple. You can understand what data is strained on huge amount of data. You're giving a huge amount of data from a very nice telescope or something. then, but it, it, it seems to predict everything perfectly, you know how a banana falls when you throw it, like everything is perfectly predicted. You still don't have a deep understanding of what governs the whole thing. Um, maybe you can ask it a question. It'll be some kind of hitchhiker's guide to the galaxy type answer. Uh, that, you know, it's a funny world we live in. Of course, it's also possible that there's no such deep, simple governing laws of nature behind the whole thing. I mean, there's something in us humans. It's possible that wants it there to be but doesn't have to be right. I do. What's, where do you again? You're betting, you already bet the farm. if, if you were to have a second farm, do you think there is a theory of everything that we might get at? So, um, simple laws that govern the whole thing?"
}