{
  "Speaker": "Greg Brockman",
  "Start": "01:10:04",
  "End": "01:11:10",
  "Text": "do do is a complex video game and we started, we started trying to solve dota because we felt like this was a step towards the real world relative to other games like chess or go, right? Those very cerebral games where you just kind of have this, very discreet moves. Dota starts to be much more continuous time that you have this huge variety of different actions that you have a 45 minute game with all these different units. And uh it's got a lot of messiness to it. Uh That, that really hasn't been captured by, by previous games. And famously, all of the hard coded bots for dota were terrible, right? It's just impossible to write anything good for it because it's so complex. And so this seemed like a really good place to push what's the state of the art in, in reinforcement learning. so we started by focusing on the one versus one version of the game. And uh and, and we're able to, to solve that, we were able to beat the world champions and that the, the, the, the learning, you know, the the skill curve was this crazy exponential, right? And it was like constantly, we were just scaling up that we were fixing bugs and you know that you look at the at the skill curve and it was really a very, very smooth one. So it's actually really interesting to see how that like human iteration loop yielded very steady exponential progress."
}