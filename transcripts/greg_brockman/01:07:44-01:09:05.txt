{
  "Speaker": "Greg Brockman",
  "Start": "01:07:44",
  "End": "01:09:05",
  "Text": "a look at, you know, I always like to look at at examples that that exist, right? Look at real precedent. And so take a look at the June 2018 model that we released, that we scaled up to turn into GP T two. you can see that at small scale, it set some records, right? This was, you know, the original GP T we actually had some some cool generations. They weren't nearly as, as, as amazing and really stunning as the GP T two ones, but it was promising it was interesting. And so I think it is the case that with a lot of these ideas that you see promise at small scale, but there is an asterisk here, a very big asterisk which is sometimes we see that emerge that are qualitatively different from anything we saw at small scale. And that the original inventor of whatever algorithm looks at and says, I didn't think I could do that. This is what we saw in dota, right? So PPO was, was created by John Sulman, who's a researcher here and uh and with, with Dota, we basically just ran PPO at massive massive scale and uh you know, there's some tweaks in order in order to make it work. But fundamentally, it's PPO at the core we were able to get this long term planning, these, these behaviors to really play out on a time scale that we just thought was not possible. Um And John looked at that and it was like, I didn't think you could do that. That's what happens when you're at three orders of magnitude more scale test to that."
}