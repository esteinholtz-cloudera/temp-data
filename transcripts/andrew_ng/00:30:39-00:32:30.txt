{
  "Speaker": "Andrew Ng",
  "Start": "00:30:39",
  "End": "00:32:30",
  "Text": "give you one example. Um when we work with uh uh manufacturing companies, um is not at all uncommon for there to be multiple labels that disagree with each other, right? And so we would um doing the work in visual inspection. Uh We will, you know, take, say a plastic pot and show it to one inspector and the inspector sometimes very opinionated. They go clearly that's a defect. The scratch unacceptable, got to reject this part. the same part to different inspector different very clearly. The scratch is small, it's fine, don't throw it away, you're going to make us, you know, and then sometimes you take the same plastic pot, show it to the same inspector in the afternoon, I suppose in the morning and very, to go in the morning to say clearly it is ok in the afternoon, equally confident. Clearly this is a defect. And so what is the A I team supposed to do if, if, if sometimes even one person doesn't agree with himself or herself in the span of a day. I think these are the types of um very practical, very messy data problems that, that, that, you know, that my teams wrestle with. Um the case of large consumer internet companies, we have a billion users. You have a lot of data, you don't worry about it just take the average, it kind of works. But in the case of other industry settings, we don't have big data if just a small data, very small data set, maybe around 100 defective parts, um or 100 examples of a defect. If you have only 100 examples, these little labeling errors, you know, if, if 10 of your 100 labels are wrong, that actually is 10% of it is that has a big impact. how do you clean this up? What are you supposed to do? This is an example of the of the types of things that um my teams, this is a landing A I example are wrestling with to deal with small data which comes up all the time. Once you're outside consumer internet. Yeah, that's"
}