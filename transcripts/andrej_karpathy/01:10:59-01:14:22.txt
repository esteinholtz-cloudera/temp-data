{
  "Speaker": "Andrej Karpathy",
  "Start": "01:10:59",
  "End": "01:14:22",
  "Text": "?. So I had a blog post on software 2.0 I think several years ago now. Um the reason I wrote that post is because I kept, I kind of saw something remarkable happening in software development and how a lot of code was being transitioned to be written, not in sort of like C++ and so on, but it's written in the weights of a neural net. Basically just saying that neural nets are taking over software, the realm of software and um taking more and more and more tasks. And at the time, I think not many people understood uh this uh deeply enough that this is a big deal. It's a big transition. Uh neural networks were seen as one of multiple classification algorithms you might use for your data set problem on Cagle. Like is not that this is a change in how we program computers. I saw neural nets as uh this is going to take over the way we program computers is going to change. It's not going to be people writing a software in C++ or something like that and directly programming the software, it's going to be accumulating training sets and data sets and crafting these objectives by which we train these neural nes. at some point, there's going to be a compilation process from the data sets and the objective and the architecture specification into the binary, which is really just uh the neural net, uh you know, weights and the forward pass of the neural net. And then you can deploy that binary. And so I was talking about that sort of transition and uh that's what the post is about. I saw this sort of play out in a lot of uh fields, uh you know, auto auto being one of them. But also just a simple image classification. People thought originally, you know, in the eighties and so on that, they would write the algorithm for detecting a dog in an image. And they had all these ideas about how the brain does it. And first we detect corners and then we detect lines and then we stitched them up and they were like really going at it. They were like thinking about how they're going to write the algorithm and this is not the way you build it. Um And there was a smooth transition where. Uh first we thought we were going to build everything, then we were building the features. Um So like hog features and things like that uh that detect these little statistical patterns from image patches. And then there was a little bit of uh learning on top of it, like a support vector machine or binary classifier uh for cat versus dog and images on top of the features. So we wrote the features, but we trained the last layer sort of the the classifier. And then people are like, actually let's not even design the features because we can't honestly, we're not very good at it. let's also learn the features. And then you end up with basically abolition neural net where you're learning most of it, you're just specifying the architecture and the architecture has tons of fill in the blanks, which is all the knobs and you let the optimization write most of it. And so this transition is happening across the industry everywhere. And uh suddenly we end up with a ton of code that is written in neural net weights. And I was just pointing out that the analogy is actually pretty strong we have a lot of developer environments for software 1.0 Like we have uh ID E um how you work with code, how you debug code, how do you, how do you run code? Uh how do you maintain code? We have github. I was trying to make those analogies in the new realm. Like what is the github a software to point out? Turns out it's something that looks like hugging face right now. Uh, you know, and so I think some people took it seriously and build cool companies and, uh many people originally attacked the Post. It actually was not well received when I wrote it and I think maybe it has something to do with the title, but the post was not well received. And I think more people sort of have been coming around to it over time."
}